%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Lachaise Assignment
% LaTeX Template
% Version 1.0 (26/6/2018)
%
% This template originates from:
% http://www.LaTeXTemplates.com
%
% Authors:
% Marion Lachaise & François Févotte
% Vel (vel@LaTeXTemplates.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%       PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[fleqn]{article}

\usepackage{amsmath}
%----------------------------------------------------------------------------------------
%       ASSIGNMENT INFORMATION
%----------------------------------------------------------------------------------------

\title{CAS MA575: Assignment \#4} % Title of the assignment

\author{Hu Hengchang(U34497427)\\ \texttt{hhc@bu.edu}} % Author name and email address

\date{Boston University --- \today} % University, school and/or department name(s) and a date

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Print the title



%------------------------------------------------

Chapter 2.2\\

Statement (d) is true, and following are my reasons:\\

Through Figure 2.8, we can easily tell that $|y_i - \hat{y_i}|$ in model 1 is smaller compare to that in model 2. Since $RSS = \sum_{i=1}^{n}(y_i - \hat{y_i})^2$, RSS of model 1 should be less than RSS of model 2.\\

And because $RSS + SSreg = SST = \sum_{i=1}^{n}(y_i - \bar{y})^2 $is fixed, RSS of model 1 is less than RSS of model 2 means that SSreg of model 1 is greater than SSreg of model 2.\\



Chapter 2.3\\

Because $y_i, y_j$ is independent when $i \neq j$, which means $cov(y_i, y_j) = 0$ when $i \neq j$.

\begin{equation*}
\begin{split}
cov(y_{n+1}, y_{n+1}+n\hat{\mu_n}) &= cov(y_{n+1}, \sum_{i=1}^{n+1}y_i)\\
&= \sum_{i=1}^{n}cov(y_{n+1}, y_i)\\
&= cov(y_{n+1}, y_{n+1})\\
&= \sigma^2
\end{split}
\end{equation*}

2.(b)

\begin{equation*}
\begin{split}
cov(\hat{\mu_n}, y_{n+1}+n\hat{\mu_n}) &= cov(\frac{1}{n}\sum_{i=1}^{n}y_i, \sum_{i=1}^{n+1}y_i)\\
&= \frac{1}{n}\sum_{i=1}^{n}\sum_{j=1}^{n+1}cov(y_i, y_j)\\
&= \frac{1}{n}\sum_{i=1}^{n}cov(y_i, y_i)\\
&= \frac{1}{n}n\sigma^2\\
&= \sigma^2
\end{split}
\end{equation*}\\

2.(c)

\begin{equation*}
\begin{split}
cov(y_{n+1}-\hat{\mu_n}, y_{n+1}+n\hat{\mu_n}) &= cov(y_{n+1}-\frac{1}{n}\sum_{i=1}^{n}y_i, \sum_{i=1}^{n+1}y_i)\\
&= cov(y_{n+1}, \sum_{i=1}^{n+1}y_i) - cov(\frac{1}{n}\sum_{i=1}^{n}y_i, \sum_{i=1}^{n+1}y_i)\\
&= \sigma^2 - \sigma^2\\
&= 0
\end{split}
\end{equation*}\\

Since $y_{n+1} - \hat{\mu_n}$ and $y_{n+1}+n\hat{\mu_n} $ are normal distribution, $cov(y_{n+1} - \hat{\mu_n}, y_{n+1}+n\hat{\mu_n}) = 0$ means that they are independent. \\


Chapter 2.6\\

(a)\\

\begin{equation*}
\begin{split}
(y_i - \hat{y_i}) &= y_i - \hat{\beta_0} - \hat{\beta_1} x_i \\
&= y_i - (\bar{y} - \hat{\beta_1} \bar{x}) - \hat{\beta_1} x_i \\
&= (y_i - \bar{y}) - \hat{\beta_1} (x_i - \bar{x})
\end{split}
\end{equation*}\\



(b)\\

\begin{equation*}
\begin{split}
(\hat{y_i} - \bar{y}) &= \hat{\beta_0} + \hat{\beta_1} x_i - \bar{y} \\
&= \bar{y} - \hat{\beta_1} \bar{x} + \hat{\beta_1} x_i - \bar{y} \\
&= \hat{\beta_1}(x_i - \bar{x})
\end{split}
\end{equation*}\\



(c)\\

\begin{equation*}
\begin{split}
\sum_{i=1}^{n}(y_i - \hat{y_i})(\hat{y_i} - \bar{y}) &= \sum_{i=1}^{n}\big[(y_i - \bar{y}) - \hat{\beta_1} (x_i - \bar{x})\big] \hat{\beta_1}(x_i - \bar{x}) \\
&= \hat{\beta_1} \Big(\sum_{i=1}^{n} (y_i - \bar{y})(x_i - \bar{x}) - \hat{\beta_1} \sum_{i=1}^{n} (x_i - \bar{x})^2 \Big) \\
&= \hat{\beta_1} \Big(SXY - \frac{SXY}{SXX} SXX\Big) \\
&= 0
\end{split}
\end{equation*}





\end{document}