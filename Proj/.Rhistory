install.packages("corrplot")
install.packages("car")
getwd()
i - 1
i = 1
i += 1
i = i + 1
i ++
i += i
?predict
head(bikedata)
#Bike Sharing
#Load data in
library(summarytools)
library(dplyr)
library(plotly)
library(lubridate)
library(tidyr)
setwd("C:\\Users\\hugo1\\Documents\\ma575\\Proj")
list.files()
bikedata <- read.csv("day.csv",header=T)
head(bikedata)
view(dfSummary(bikedata))
hist(bikedata$casual)
# visulization graphs
# long to wide
p <- plot_ly(bikedata, x = ~dteday, y = ~casual, type = 'bar',text = ~casual, textposition = 'auto', name = 'casual') %>%
add_trace(y = ~registered,text = w~registered, textposition = 'auto', name = 'registered') %>%
layout(yaxis = list(title = 'Count'), barmode = 'stack')
p
# the counts have grown for both registered and casual
#split the data into training and validation
head(bikedata)
dim(bikedata)
#731 rows in total, 70% (511), 30% (220)
bikedata_train <- bikedata[1:511,]
bikedata_test <- bikedata[512:731,]
# predict the number of casual bike rides based on season, temperature, humidity and windspeed
lm_bike <- lm(cnt ~ season + yr + mnth + holiday + weekday + workingday + weathersit + atemp  + hum + windspeed
,  data = bikedata_train)
summary(lm_bike)
# R^2 is 0.7743
# Predict the values of the test set: pred
pred <- predict(lm_bike,bikedata_test)
head(pred)
# Calculate rmse2
rmse <- sqrt(sum( (bikedata_test$cnt - pred) ^ 2) / nrow(bikedata_test))
rmse #1121.714
# Construct the confusion matrix: conf
conf = table(test$Survived,pred)
setwd("C:\\Users\\hugo1\\Documents\\ma575\\Proj")
list.files()
bikedata <- read.csv("day.csv",header=T)
head(bikedata)
hist(bikedata$casual)
p <- plot_ly(bikedata, x = ~dteday, y = ~casual, type = 'bar',text = ~casual, textposition = 'auto', name = 'casual') %>%
add_trace(y = ~registered,text = w~registered, textposition = 'auto', name = 'registered') %>%
layout(yaxis = list(title = 'Count'), barmode = 'stack')
#Bike Sharing
#Load data in
library(summarytools)
install.packages("summarytools")
install.packages("dplyr")
install.packages("plotly")
install.packages("lubridate")
install.packages("tidyr")
library(summarytools)
library(dplyr)
library(plotly)
library(lubridate)
library(tidyr)
p <- plot_ly(bikedata, x = ~dteday, y = ~casual, type = 'bar',text = ~casual, textposition = 'auto', name = 'casual') %>%
add_trace(y = ~registered,text = w~registered, textposition = 'auto', name = 'registered') %>%
layout(yaxis = list(title = 'Count'), barmode = 'stack')
p
#split the data into training and validation
head(bikedata)
bikedata_train <- bikedata %>% filter(yr == 0)
bikedata_test <- bikedata %>% filter(yr == 1)
View(bikedata)
X <- bikedata %>% select(-instant, -dteday)
c <- cor(X)
round(c,3)
res1 <- cor.mtest(X, conf.level = .95)
library(corrplot)
res1 <- cor.mtest(X, conf.level = .95)
## corrplot 0.84 loaded
corrplot(round(c,3),p.mat = res1$p, sig.level = .05, type = "upper")
View(bikedata)
install.packages("polycor")
library(polycor)
corr_data <- bikedata %>% select(-instant, -dteday)
#Heterogenous correlation matrix
res2 <- hetcor(corr_data)
#adjust correlation matrix
corrMatrix <- res2$correlations
diag(corrMatrix) <- 0
corrplot(corrMatrix, method = "number", type = "upper", sig.level =0.01)
class(corr_data$holiday)
corr_data$workingday = as.factor(corr_data$workingday)
corr_data$holiday = as.factor(corr_data$holiday)
corr_data$mnth = as.factor(corr_data$mnth)
#Heterogenous correlation matrix
res2 <- hetcor(corr_data)
#adjust correlation matrix
corrMatrix <- res2$correlations
diag(corrMatrix) <- 0
corrplot(corrMatrix, method = "number", type = "upper", sig.level =0.01)
corr_data$workingday = as.factor(corr_data$workingday)
corr_data$holiday = as.factor(corr_data$holiday)
corr_data$mnth = as.factor(corr_data$mnth)
corr_data$season = as.factor(corr_data$season)
corr_data$yr = as.factor(corr_data$yr)
corr_data$weekday = as.factor(corr_data$weekday)
#Heterogenous correlation matrix
res2 <- hetcor(corr_data)
#adjust correlation matrix
corrMatrix <- res2$correlations
diag(corrMatrix) <- 0
corrplot(corrMatrix, method = "number", type = "upper", sig.level =0.01)
# predict the number of casual bike rides based on season, temperature, humidity and windspeed
lm_bike <- lm(cnt ~ season + holiday + weekday + weathersit + atemp + windspeed
,  data = bikedata_train)
summary(lm_bike)
# Predict the values of the test set: pred
pred <- predict(lm_bike,bikedata_test)
ResMLSValidation <- bikedata_test$cnt - pred$fit
# Predict the values of the test set: pred
pred <- predict(lm_bike, se.fit = TRUE, bikedata_test)
ResMLSValidation <- bikedata_test$cnt - pred$fit
points(bikedata_test$cnt, ResMLSValidation, xlab="count", ylab="Residuals",xlim=c(0,7),col="red")
plot(bikedata_train$cnt, ResMLS,xlab="count", ylab="Residuals",xlim=c(0,7), col="blue")
ResMLS <- resid(lm_bike)
par(mfrow=c(1,1))
plot(bikedata_train$cnt, ResMLS,xlab="count", ylab="Residuals",xlim=c(0,7), col="blue")
plot(bikedata_train$cnt, ResMLS,xlab="count", ylab="Residuals", col="blue")
points(bikedata_test$cnt, ResMLSValidation, xlab="count", ylab="Residuals",col="red")
plot(bikedata_train$cnt / mean(bikedata_train$cnt), ResMLS,xlab="count", ylab="Residuals", col="blue")
points(bikedata_test$cnt / mean(bikedata_test$cnt), ResMLSValidation, xlab="count", ylab="Residuals",col="red")
#731 rows in total, 50% , 50%
total_cnt_sum <- bikedata %>%
group_by(yr) %>%
summarize(total_cnt = sum(cnt))
bikedata <- bikedata %>%
left_join(total_cnt_sum) %>%
mutate(Perentage = cnt/total_cnt)
bikedata_train <- bikedata %>% filter(yr == 0)
bikedata_test <- bikedata %>% filter(yr == 1)
corr_data <- bikedata %>% select(-instant, -dteday)
c <- cor(corr_data)
round(c,3)
res1 <- cor.mtest(corr_data, conf.level = .95)
## corrplot 0.84 loaded
corrplot(round(c,3),p.mat = res1$p, sig.level = .05, type = "upper")
corr_data$workingday = as.factor(corr_data$workingday)
corr_data$holiday = as.factor(corr_data$holiday)
corr_data$mnth = as.factor(corr_data$mnth)
corr_data$season = as.factor(corr_data$season)
corr_data$yr = as.factor(corr_data$yr)
corr_data$weekday = as.factor(corr_data$weekday)
#Heterogenous correlation matrix
res2 <- hetcor(corr_data)
#adjust correlation matrix
corrMatrix <- res2$correlations
diag(corrMatrix) <- 0
corrplot(corrMatrix, method = "number", type = "upper", sig.level =0.01)
# predict the number of casual bike rides based on season, temperature, humidity and windspeed
lm_bike <- lm(cnt ~ season + holiday + weekday + weathersit + atemp + windspeed
,  data = bikedata_train)
summary(lm_bike)
# predict the number of casual bike rides based on season, temperature, humidity and windspeed
lm_bike <- lm(perentage ~ season + holiday + weekday + weathersit + atemp + windspeed
,  data = bikedata_train)
# predict the number of casual bike rides based on season, temperature, humidity and windspeed
lm_bike <- lm(Perentage ~ season + holiday + weekday + weathersit + atemp + windspeed
,  data = bikedata_train)
summary(lm_bike)
# Predict the values of the test set: pred
pred <- predict(lm_bike, se.fit = TRUE, bikedata_test)
head(pred)
ResMLSValidation <- bikedata_test$cnt - pred$fit
ResMLS <- resid(lm_bike)
ResMLSValidation <- bikedata_test$Perentage - pred$fit
ResMLS <- resid(lm_bike)
par(mfrow=c(1,1))
plot(bikedata_train$cnt / mean(bikedata_train$cnt), ResMLS,xlab="count", ylab="Residuals", col="blue")
points(bikedata_test$cnt / mean(bikedata_test$cnt), ResMLSValidation, xlab="count", ylab="Residuals",col="red")
plot(bikedata_train$Perentage, ResMLS,xlab="count", ylab="Residuals", col="blue")
points(bikedata_test$Perentage, ResMLSValidation, xlab="count", ylab="Residuals",col="red")
# Mean Square Error for training data
mean((ResMLS)^2)
# Mean Square Error for validation data
mean((ResMLSValidation)^2)
# Standarized Residuals
StanResMLS <- rstandard(lm_bike)
par(mfrow=c(1,1))
plot(bikedata_train$Perentage ,StanResMLS, xlab="Percentage", ylab="Standardized Residuals", col="blue") +abline(h=2,lty=2) + abline(h=-2,lty=2)
# Test of Normality for Standarized Residuals of QMLS and QuartLS
q1 <- qqnorm(StanResMLS, plot.it = TRUE)
# This doesn't work me either
qqline(StanResMLS,lty = 2)
# Histogram of QMLS and QuartLS
par(mfrow=c(1,1))
hist(StanResMLS,100)
